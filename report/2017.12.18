1.神经网络架构：输入层-隐藏层-输入层（即MLP）
2.前馈/正反馈（feedforward）神经网络：网络中没有回路，信息总是向前传播，从不反馈，递归（recurrent）神经网络：带反馈环路
3.练习：设额外层的四个神经元分别是B3B2B1B0，并且他们的bais都为-10，则：
  对于B0，W0=W2=W4=W6=W8=-9，W1=W3=W5=W7=W9=11，
  对于B1，W0=W1=W4=W5=W8=W9=-9，W2=W3=W6=W7=11，
  对于B2，W0=W1=W2=W3=W8=W9=-9，W4=W5=W6=W7=11，
  对于B3，W0=W1=...=W7=-9，W8=W9=11
4.C(w,x)=(1/2n)Σ(x)(||y(x)-a||^2)被称为二次(quadratic)代价函数（损失函数/目标函数）,y(x)是输入为x时的期望输出，a是实际输出，w是权重的集合，b是
  所有的偏置，n是输入数据的个数，C(w,x)越趋于零越好，所以训练神经网络的目的是找到能最小化C(w,x)的权重和偏置，用梯度下降算法来解决
5.练习：由柯西-施瓦茨不等式知,(∇C · ∆v)^2<=||∇C||^2*||∆v||^2=||∇C||^2*ϵ^2,即-||∇C||*ϵ<=∇C · ∆v<=||∇C||*ϵ，所以，当∆v=(-ϵ/||∇C||)*∇C时，
  ∇C · ∆v取得最小值
